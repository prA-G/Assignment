{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7437d633",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "What is Detectron2 and how does it differ from previous object detection frameworks?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Detectron2 is an open-source computer vision framework developed by Facebook AI\n",
    "Research. It is built on PyTorch and is used for tasks like object detection,\n",
    "instance segmentation, and keypoint detection.\n",
    "\n",
    "Detectron2 differs from older object detection frameworks in the following ways:\n",
    "\n",
    "- It is based on PyTorch, which makes model development and debugging easier.\n",
    "- It has a modular and flexible design, allowing easy customization.\n",
    "- It provides better performance and speed compared to older frameworks like\n",
    "  Detectron (Caffe2-based).\n",
    "- It supports modern and state-of-the-art detection models.\n",
    "- It includes built-in evaluation and visualization tools.\n",
    "\n",
    "Overall, Detectron2 is more efficient, user-friendly, and suitable for both\n",
    "research and real-world applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444837b",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Explain the process and importance of data annotation when working with Detectron2.\n",
    "\n",
    "### Answer\n",
    "\n",
    "Data annotation is the process of labeling objects in images so that a model can\n",
    "learn to recognize them. In Detectron2, annotations usually include bounding\n",
    "boxes, class labels, and sometimes segmentation masks.\n",
    "\n",
    "The process involves:\n",
    "- Collecting images\n",
    "- Labeling objects using annotation tools\n",
    "- Saving annotations in formats like COCO\n",
    "- Loading the annotated data into Detectron2 for training\n",
    "\n",
    "Data annotation is important because:\n",
    "- The model learns only from labeled data\n",
    "- Accurate annotations improve model accuracy\n",
    "- Poor or incorrect labels lead to wrong predictions\n",
    "\n",
    "In short, good data annotation is the foundation of training an effective\n",
    "Detectron2 model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefca9b",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Describe the steps involved in training a custom object detection model using Detectron2.\n",
    "\n",
    "### Answer\n",
    "\n",
    "The steps to train a custom object detection model using Detectron2 are:\n",
    "\n",
    "1. Prepare and annotate the dataset in COCO format.\n",
    "2. Register the training and validation datasets in Detectron2.\n",
    "3. Choose a pre-trained model from the Detectron2 model zoo.\n",
    "4. Configure the model settings like number of classes, learning rate, and\n",
    "   batch size.\n",
    "5. Train the model using the training script.\n",
    "6. Evaluate the model using validation data.\n",
    "7. Save the trained model weights for inference.\n",
    "\n",
    "These steps help in building and training a custom object detection model\n",
    "successfully using Detectron2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291b910",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "What are evaluation curves in Detectron2, and how are metrics like mAP and IoU interpreted?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Evaluation curves in Detectron2 are used to measure how well an object detection\n",
    "model is performing. These curves help understand the accuracy and reliability\n",
    "of the model.\n",
    "\n",
    "IoU (Intersection over Union) measures how much the predicted bounding box\n",
    "overlaps with the ground truth box. A higher IoU means better prediction.\n",
    "\n",
    "mAP (mean Average Precision) is the main evaluation metric in object detection.\n",
    "It shows the overall detection accuracy of the model across different classes\n",
    "and IoU thresholds.\n",
    "\n",
    "In simple terms, IoU checks how correct a single prediction is, while mAP\n",
    "summarizes the modelâ€™s overall performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa33e39",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Compare Detectron2 and TFOD2 in terms of features, performance, and ease of use.\n",
    "\n",
    "### Answer\n",
    "\n",
    "Detectron2 and TFOD2 are both popular object detection frameworks, but they have\n",
    "some differences.\n",
    "\n",
    "Detectron2:\n",
    "- Built on PyTorch\n",
    "- Easy to customize and experiment with\n",
    "- Better performance for research and advanced models\n",
    "- Preferred in research and academic work\n",
    "\n",
    "TFOD2 (TensorFlow Object Detection API):\n",
    "- Built on TensorFlow\n",
    "- More beginner-friendly\n",
    "- Good for deployment and production\n",
    "- Strong integration with TensorFlow tools\n",
    "\n",
    "In short, Detectron2 is more flexible and powerful for research, while TFOD2 is\n",
    "easier to use and better suited for production environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a326e",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Write Python code to install Detectron2 and verify the installation.\n",
    "\n",
    "### Answer\n",
    "\n",
    "The following code shows how Detectron2 can be installed and verified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eea647",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b594293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch2.0/index.html\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement detectron2 (from versions: none)\n",
      "ERROR: No matching distribution found for detectron2\n"
     ]
    }
   ],
   "source": [
    "# Install Detectron2 (Linux / Colab supported)\n",
    "%pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch2.0/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457ce6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectron2 installation requires Linux or Colab environment\n"
     ]
    }
   ],
   "source": [
    "# Verify installation\n",
    "try:\n",
    "    import detectron2\n",
    "    print(\"Detectron2 installed successfully\")\n",
    "except:\n",
    "    print(\"Detectron2 installation requires Linux or Colab environment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdc6b7a",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Annotate a dataset using any tool of your choice and convert the annotations to COCO format for Detectron2.\n",
    "\n",
    "### Answer\n",
    "\n",
    "Dataset annotation means labeling objects in images using tools like LabelImg\n",
    "or CVAT. The annotated data is then converted into COCO format, which is\n",
    "required by Detectron2.\n",
    "\n",
    "Steps followed:\n",
    "1. Collect images for the dataset.\n",
    "2. Annotate images using an annotation tool.\n",
    "3. Export annotations in JSON format.\n",
    "4. Convert annotations to COCO format.\n",
    "5. Use the COCO file for training in Detectron2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bff7c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations converted to COCO format\n"
     ]
    }
   ],
   "source": [
    "# Example: Converting annotations to COCO format (simplified)\n",
    "\n",
    "import json\n",
    "\n",
    "coco_format = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": [\n",
    "        {\"id\": 1, \"name\": \"object\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"annotations.json\", \"w\") as f:\n",
    "    json.dump(coco_format, f)\n",
    "\n",
    "print(\"Annotations converted to COCO format\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2971acd",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "Write a script to download pretrained weights and configure paths for training in Detectron2.\n",
    "\n",
    "### Answer\n",
    "\n",
    "Detectron2 provides pretrained model weights through its model zoo.\n",
    "These weights help in faster training and better accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained weights and configure model paths\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Load configuration from model zoo\n",
    "cfg.merge_from_file(\n",
    "    model_zoo.get_config_file(\n",
    "        \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Set pretrained weights\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "    \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
    ")\n",
    "\n",
    "# Set output directory\n",
    "cfg.OUTPUT_DIR = \"./output\"\n",
    "\n",
    "print(\"Pretrained weights loaded and paths configured\")\n",
    "\n",
    "\n",
    "try:\n",
    "    import detectron2\n",
    "    from detectron2 import model_zoo\n",
    "    from detectron2.config import get_cfg\n",
    "    print(\"Detectron2 is available\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Detectron2 is not installed. Code requires Linux/Colab environment.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717e016",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "Show the steps and code to run inference using a trained Detectron2 model on a new image.\n",
    "\n",
    "### Answer\n",
    "\n",
    "Inference means using a trained model to detect objects in a new image.\n",
    "In Detectron2, this is done using a predictor that loads the trained weights\n",
    "and runs detection on the input image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4613a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectron2 is not installed. Inference requires Linux or Colab.\n"
     ]
    }
   ],
   "source": [
    "# Run inference using Detectron2 (Linux / Colab environment)\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    from detectron2.engine import DefaultPredictor\n",
    "    from detectron2.config import get_cfg\n",
    "    from detectron2 import model_zoo\n",
    "\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(\n",
    "        model_zoo.get_config_file(\n",
    "            \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
    "        )\n",
    "    )\n",
    "    cfg.MODEL.WEIGHTS = \"model_final.pth\"  # trained model weights\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "    cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    image = cv2.imread(\"test.jpg\")\n",
    "    outputs = predictor(image)\n",
    "\n",
    "    print(\"Inference completed successfully\")\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Detectron2 is not installed. Inference requires Linux or Colab.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d719b",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "You are assigned to build a wildlife monitoring system to detect and track\n",
    "different animal species in a forest using Detectron2. Describe the end-to-end\n",
    "pipeline from data collection to deploying the model, and how you would handle\n",
    "challenges like occlusion or nighttime detection.\n",
    "\n",
    "### Answer\n",
    "\n",
    "The end-to-end pipeline for a wildlife monitoring system using Detectron2 is as\n",
    "follows:\n",
    "\n",
    "1. **Data Collection**\n",
    "   - Capture images and videos using forest cameras and drones.\n",
    "   - Collect data during day and night for better coverage.\n",
    "\n",
    "2. **Data Annotation**\n",
    "   - Annotate animals using tools like LabelImg.\n",
    "   - Convert annotations into COCO format for Detectron2.\n",
    "\n",
    "3. **Model Training**\n",
    "   - Use a pretrained Detectron2 model.\n",
    "   - Train the model on the annotated wildlife dataset.\n",
    "\n",
    "4. **Evaluation**\n",
    "   - Evaluate the model using metrics like mAP and IoU.\n",
    "   - Improve the model by adding more data if needed.\n",
    "\n",
    "5. **Inference and Deployment**\n",
    "   - Run inference on new images or live camera feeds.\n",
    "   - Deploy the model on edge devices or cloud servers.\n",
    "\n",
    "### Handling Challenges\n",
    "\n",
    "- **Occlusion**: Use more training data with partially visible animals and data\n",
    "  augmentation.\n",
    "- **Nighttime Detection**: Include infrared or low-light images in training.\n",
    "- **False Detections**: Tune confidence thresholds and retrain with better data.\n",
    "\n",
    "This pipeline helps in building an efficient and reliable wildlife monitoring\n",
    "system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad146f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load trained Detectron2 model\n",
      "Run detection on wildlife image\n",
      "Display detected animal species\n"
     ]
    }
   ],
   "source": [
    "# Sample inference pipeline (conceptual)\n",
    "\n",
    "def wildlife_inference(image_path):\n",
    "    print(\"Load trained Detectron2 model\")\n",
    "    print(\"Run detection on wildlife image\")\n",
    "    print(\"Display detected animal species\")\n",
    "\n",
    "wildlife_inference(\"forest_image.jpg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
